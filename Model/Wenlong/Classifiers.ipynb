{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare utility functions\n",
    "TARGET_COL = 622\n",
    "FEATURE = 0\n",
    "TARGET = 1\n",
    "\n",
    "def get_csv(path):\n",
    "    data = pd.read_csv(filepath_or_buffer=path, header=None)\n",
    "    # all train data\n",
    "    X = data.iloc[:,4:-1]\n",
    "    # all test data\n",
    "    Y = data.iloc[:, -1:][TARGET_COL]\n",
    "    return (X, Y, data)\n",
    "\n",
    "def part_list(lst, n):\n",
    "    \"\"\"\n",
    "        part_list: Partition lst balanced parts\n",
    "        in: \n",
    "            lst - list that needs to be partitioned\n",
    "            n - integer number of partitions\n",
    "        out:\n",
    "            partitioned list\n",
    "    \"\"\"\n",
    "    parts, rest = divmod(len(lst), n)\n",
    "    lstiter = iter(lst)\n",
    "    for j in xrange(n):\n",
    "        plen = len(lst)/n + (1 if rest > 0 else 0)\n",
    "        rest -= 1\n",
    "        yield list(itertools.islice(lstiter, plen))\n",
    "\n",
    "def build_group_df(data, patients):\n",
    "    \"\"\"\n",
    "        build_group_df: helper for build_cross_validation_sets\n",
    "        in: \n",
    "            data - RAW data\n",
    "            patients - list of patient ids\n",
    "        out:\n",
    "            df with concatenated pixel data relevant to each patient in patients\n",
    "    \"\"\"\n",
    "    return pd.concat([data[data[0] == patient] for patient in patients], ignore_index=True)\n",
    "\n",
    "def build_cross_validation_sets(data, k):\n",
    "    \"\"\"\n",
    "        build_cross_validation_sets: helper for cross_validate\n",
    "        in:\n",
    "            data: RAW data\n",
    "            k - desire number of groups\n",
    "        out:\n",
    "            list of tuples: (feature_df, target_series)\n",
    "    \"\"\"\n",
    "    # manifest constants, get unique patients, and random shuffle\n",
    "    unique_patients = data[0].unique().tolist()\n",
    "    random.shuffle(unique_patients)\n",
    "\n",
    "    #create k groups\n",
    "    k_groups = list(part_list(unique_patients, k))\n",
    "    \n",
    "    # [df1, df2, df3, df4] with each dfi repersenting the ith group in k total groups\n",
    "    k_df = [build_group_df(data, group) for group in k_groups]\n",
    "    # (features, target) for each df\n",
    "    k_df_split = [(data.iloc[:,3:-1], data.iloc[:, -1:][TARGET_COL]) for data in k_df]\n",
    "    \n",
    "    return k_df_split\n",
    "    \n",
    "def cross_validate(model, data, k = 5):\n",
    "    \"\"\"\n",
    "        cross_validate: performs cross validation\n",
    "        in:\n",
    "            model - input model\n",
    "            data - RAW data\n",
    "            k - desired number of groups\n",
    "        out:\n",
    "            (mean of scores, list of scores)\n",
    "    \"\"\"\n",
    "    # manifest constants\n",
    "    score_list = []\n",
    "    \n",
    "    # get split data\n",
    "    k_df_split = build_cross_validation_sets(data, k)\n",
    "    \n",
    "    for (i, (X, y)) in enumerate(k_df_split):\n",
    "        # get all dfs not k\n",
    "        non_kth_group = k_df_split[:]\n",
    "        del non_kth_group[i]\n",
    "        \n",
    "        # build x and y train data\n",
    "        X_train = pd.concat([data[FEATURE] for data in non_kth_group])\n",
    "        y_train = pd.concat([data[TARGET] for data in non_kth_group])\n",
    "        \n",
    "        # build x and y test data\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "        \n",
    "        # train model on non_kth_group\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # test model on kth group\n",
    "        score = model.score(X_test, y_test)\n",
    "        \n",
    "        # add score to score list\n",
    "        score_list.append(score)\n",
    "        \n",
    "    return (np.mean(score_list), score_list)\n",
    "\n",
    "#data.sort_values(0)\n",
    "#build_cross_validation_sets(data, 5)\n",
    "#cross_validate(LRmodel, data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, data = get_csv('./data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNaiveBayes: 0.7047\n",
      "MultinomialNaiveBayes: 0.6602\n",
      "BernoulliNaiveBayes: 0.5031\n",
      "NeuralNetwork: 0.6719\n",
      "LogisticRegression: 0.7480\n"
     ]
    }
   ],
   "source": [
    "gnb = [GaussianNB(), 'GaussianNaiveBayes'] # < this one\n",
    "mnb = [MultinomialNB(), 'MultinomialNaiveBayes']\n",
    "bnb = [BernoulliNB(), 'BernoulliNaiveBayes'] # < not this one\n",
    "kn_5 = [KNeighborsClassifier(5), 'KNeighbors5']\n",
    "nn = [MLPClassifier(), 'NeuralNetwork']\n",
    "lr = [LogisticRegression(), 'LogisticRegression']\n",
    "rbf = [RBF(), 'RBF SVM']\n",
    "svc = [SVC(), 'SVC']\n",
    "\n",
    "\n",
    "models = [gnb, mnb, bnb, nn, lr, svc, rbf, kn_5]\n",
    "\n",
    "for each in models:\n",
    "    model, name = each\n",
    "    score, score_list = cross_validate(model, data, 5)\n",
    "    print(name + \": {:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

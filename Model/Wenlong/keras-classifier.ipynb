{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import tensorflow\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import backend\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings for KerasWrapper Class\n",
    "keras_settings = {}\n",
    "keras_settings['epochs'] = 10\n",
    "keras_settings['batch_size'] = 100\n",
    "keras_settings['verbose'] = 1\n",
    "keras_settings['validation_split'] = 0.0\n",
    "keras_settings['validation_data'] = None\n",
    "keras_settings['shuffle'] = True\n",
    "\n",
    "keras_settings['optimizer'] = 'adadelta'\n",
    "keras_settings['loss'] = 'binary_crossentropy'\n",
    "keras_settings['metrics'] = ['accuracy']\n",
    "\n",
    "# Wrapper class for Sequential Neural Network\n",
    "class KerasSequential(Sequential):\n",
    "    # settings contains several variables for the fit and score functions\n",
    "    def __init__(self, settings = None, layers=None, name=None):\n",
    "        Sequential.__init__(self, layers, name)\n",
    "        self.settings = settings\n",
    "    \n",
    "    # Fits sequential model to test batch\n",
    "    def fit(self, X, y):\n",
    "        Sequential.compile(self,\n",
    "                           optimizer = self.settings['optimizer'],\n",
    "                           loss = self.settings['loss'],\n",
    "                           metrics = self.settings['metrics'])\n",
    "        return Sequential.fit(self, np.array(X), y,\n",
    "                 epochs = self.settings['epochs'],\n",
    "                 batch_size = self.settings['batch_size'],\n",
    "                 verbose = self.settings['verbose'],\n",
    "                 validation_split = self.settings['validation_split'],\n",
    "                 validation_data = self.settings['validation_data'],\n",
    "                 shuffle = self.settings['shuffle'])\n",
    "    \n",
    "    # Returns the accuracy of the test batch\n",
    "    def score(self, X_test, y_test):\n",
    "        score =  Sequential.evaluate(self, np.array(X_test), y_test,\n",
    "                               batch_size = self.settings['batch_size'],\n",
    "                               verbose = self.settings['verbose'])\n",
    "        return score[1] if self.settings['metrics'] != None else score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# declare utility functions\n",
    "TARGET_COL = 622\n",
    "FEATURE = 0\n",
    "TARGET = 1\n",
    "\n",
    "def get_csv(path):\n",
    "    data = pd.read_csv(filepath_or_buffer=path, header=None)\n",
    "    # all train data\n",
    "    X = data.iloc[:,4:-1]\n",
    "    # all test data\n",
    "    Y = data.iloc[:, -1:][TARGET_COL]\n",
    "    return (X, Y, data)\n",
    "\n",
    "def part_list(lst, n):\n",
    "    \"\"\"\n",
    "        part_list: Partition lst balanced parts\n",
    "        in: \n",
    "            lst - list that needs to be partitioned\n",
    "            n - integer number of partitions\n",
    "        out:\n",
    "            partitioned list\n",
    "    \"\"\"\n",
    "    parts, rest = divmod(len(lst), n)\n",
    "    lstiter = iter(lst)\n",
    "    for j in xrange(n):\n",
    "        plen = len(lst)/n + (1 if rest > 0 else 0)\n",
    "        rest -= 1\n",
    "        yield list(itertools.islice(lstiter, plen))\n",
    "\n",
    "def build_group_df(data, patients):\n",
    "    \"\"\"\n",
    "        build_group_df: helper for build_cross_validation_sets\n",
    "        in: \n",
    "            data - RAW data\n",
    "            patients - list of patient ids\n",
    "        out:\n",
    "            df with concatenated pixel data relevant to each patient in patients\n",
    "    \"\"\"\n",
    "    return pd.concat([data[data[0] == patient] for patient in patients], ignore_index=True)\n",
    "\n",
    "def build_cross_validation_sets(data, k):\n",
    "    \"\"\"\n",
    "        build_cross_validation_sets: helper for cross_validate\n",
    "        in:\n",
    "            data: RAW data\n",
    "            k - desire number of groups\n",
    "        out:\n",
    "            list of tuples: (feature_df, target_series)\n",
    "    \"\"\"\n",
    "    # manifest constants, get unique patients, and random shuffle\n",
    "    unique_patients = data[0].unique().tolist()\n",
    "    random.shuffle(unique_patients)\n",
    "\n",
    "    #create k groups\n",
    "    k_groups = list(part_list(unique_patients, k))\n",
    "    \n",
    "    # [df1, df2, df3, df4] with each dfi repersenting the ith group in k total groups\n",
    "    k_df = [build_group_df(data, group) for group in k_groups]\n",
    "    # (features, target) for each df\n",
    "    k_df_split = [(data.iloc[:,4:-1], data.iloc[:, -1:][TARGET_COL]) for data in k_df]\n",
    "    \n",
    "    return k_df_split\n",
    "    \n",
    "def cross_validate(model, data, k = 5):\n",
    "    \"\"\"\n",
    "        cross_validate: performs cross validation\n",
    "        in:\n",
    "            model - input model\n",
    "            data - RAW data\n",
    "            k - desired number of groups\n",
    "        out:\n",
    "            (mean of scores, list of scores)\n",
    "    \"\"\"\n",
    "    # manifest constants\n",
    "    score_list = []\n",
    "    \n",
    "    # get split data\n",
    "    k_df_split = build_cross_validation_sets(data, k)\n",
    "    \n",
    "    for (i, (X, y)) in enumerate(k_df_split):\n",
    "        # get all dfs not k\n",
    "        non_kth_group = k_df_split[:]\n",
    "        del non_kth_group[i]\n",
    "        \n",
    "        # build x and y train data\n",
    "        X_train = pd.concat([data[FEATURE] for data in non_kth_group])\n",
    "        y_train = pd.concat([data[TARGET] for data in non_kth_group])\n",
    "        \n",
    "        # build x and y test data\n",
    "        X_test = X\n",
    "        y_test = y\n",
    "        \n",
    "        # train model on non_kth_group\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # test model on kth group\n",
    "        score = model.score(X_test, y_test)\n",
    "        \n",
    "        # add score to score list\n",
    "        score_list.append(score)\n",
    "        \n",
    "    return (np.mean(score_list), score_list)\n",
    "\n",
    "#data.sort_values(0)\n",
    "#build_cross_validation_sets(data, 5)\n",
    "#cross_validate(LRmodel, data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "X, y, data = get_csv('data/train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41369/41369 [==============================] - 5s - loss: 0.4937 - acc: 0.7650     \n",
      "Epoch 2/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.4001 - acc: 0.8191     \n",
      "Epoch 3/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.3672 - acc: 0.8359     \n",
      "Epoch 4/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.3412 - acc: 0.8503     \n",
      "Epoch 5/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.3129 - acc: 0.8671     \n",
      "Epoch 6/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.2985 - acc: 0.8731     \n",
      "Epoch 7/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.2834 - acc: 0.8808     \n",
      "Epoch 8/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.2708 - acc: 0.8865     \n",
      "Epoch 9/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.2606 - acc: 0.8917     \n",
      "Epoch 10/10\n",
      "41369/41369 [==============================] - 4s - loss: 0.2531 - acc: 0.8955     \n",
      "8100/8631 [===========================>..] - ETA: 0sEpoch 1/10\n",
      "40174/40174 [==============================] - 5s - loss: 0.2679 - acc: 0.8880     \n",
      "Epoch 2/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.2437 - acc: 0.9004     \n",
      "Epoch 3/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.2272 - acc: 0.9063     \n",
      "Epoch 4/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.2172 - acc: 0.9130     \n",
      "Epoch 5/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.2086 - acc: 0.9167     \n",
      "Epoch 6/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.1995 - acc: 0.9209     \n",
      "Epoch 7/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.1924 - acc: 0.9245     \n",
      "Epoch 8/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.1872 - acc: 0.9262     \n",
      "Epoch 9/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.1836 - acc: 0.9268     \n",
      "Epoch 10/10\n",
      "40174/40174 [==============================] - 4s - loss: 0.1805 - acc: 0.9291     \n",
      "9600/9826 [============================>.] - ETA: 0sEpoch 1/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.2281 - acc: 0.9057     \n",
      "Epoch 2/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.2013 - acc: 0.9192     \n",
      "Epoch 3/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1930 - acc: 0.9224     \n",
      "Epoch 4/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1846 - acc: 0.9265     \n",
      "Epoch 5/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1816 - acc: 0.9283     \n",
      "Epoch 6/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1753 - acc: 0.9310     \n",
      "Epoch 7/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1691 - acc: 0.9332     \n",
      "Epoch 8/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1679 - acc: 0.9341     \n",
      "Epoch 9/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1626 - acc: 0.9372     \n",
      "Epoch 10/10\n",
      "38974/38974 [==============================] - 4s - loss: 0.1562 - acc: 0.9398     \n",
      "11000/11026 [============================>.] - ETA: 0sEpoch 1/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1846 - acc: 0.9249     \n",
      "Epoch 2/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1654 - acc: 0.9333     \n",
      "Epoch 3/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1606 - acc: 0.9361     \n",
      "Epoch 4/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1562 - acc: 0.9379     \n",
      "Epoch 5/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1522 - acc: 0.9399     \n",
      "Epoch 6/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1505 - acc: 0.9410     \n",
      "Epoch 7/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1465 - acc: 0.9412     \n",
      "Epoch 8/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1446 - acc: 0.9430     \n",
      "Epoch 9/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1414 - acc: 0.9437     \n",
      "Epoch 10/10\n",
      "38922/38922 [==============================] - 4s - loss: 0.1394 - acc: 0.9449     \n",
      " 9700/11078 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "40561/40561 [==============================] - 5s - loss: 0.1592 - acc: 0.9384     \n",
      "Epoch 2/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1479 - acc: 0.9431     \n",
      "Epoch 3/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1416 - acc: 0.9453     \n",
      "Epoch 4/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1416 - acc: 0.9455     \n",
      "Epoch 5/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1401 - acc: 0.9468     \n",
      "Epoch 6/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1345 - acc: 0.9481     \n",
      "Epoch 7/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1353 - acc: 0.9489     \n",
      "Epoch 8/10\n",
      "40561/40561 [==============================] - 4s - loss: 0.1323 - acc: 0.9485     \n",
      "Epoch 9/10\n",
      "40561/40561 [==============================] - 5s - loss: 0.1298 - acc: 0.9504     \n",
      "Epoch 10/10\n",
      "40561/40561 [==============================] - 5s - loss: 0.1311 - acc: 0.9494     \n",
      "9100/9439 [===========================>..] - ETA: 0sEpoch 1/10\n",
      "39598/39598 [==============================] - 5s - loss: 0.1388 - acc: 0.9465     \n",
      "Epoch 2/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1302 - acc: 0.9515     \n",
      "Epoch 3/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1261 - acc: 0.9515     \n",
      "Epoch 4/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1257 - acc: 0.9529     \n",
      "Epoch 5/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1232 - acc: 0.9534     \n",
      "Epoch 6/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1206 - acc: 0.9529     \n",
      "Epoch 7/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1206 - acc: 0.9547     \n",
      "Epoch 8/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1188 - acc: 0.9559     \n",
      "Epoch 9/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1182 - acc: 0.9556     \n",
      "Epoch 10/10\n",
      "39598/39598 [==============================] - 4s - loss: 0.1173 - acc: 0.9564     \n",
      "10300/10402 [============================>.] - ETA: 0sEpoch 1/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1417 - acc: 0.9468     \n",
      "Epoch 2/10\n",
      "41577/41577 [==============================] - 4s - loss: 0.1326 - acc: 0.9491     \n",
      "Epoch 3/10\n",
      "41577/41577 [==============================] - 4s - loss: 0.1294 - acc: 0.9498     \n",
      "Epoch 4/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1286 - acc: 0.9505     \n",
      "Epoch 5/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1242 - acc: 0.9523     \n",
      "Epoch 6/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1237 - acc: 0.9528     \n",
      "Epoch 7/10\n",
      "41577/41577 [==============================] - 4s - loss: 0.1222 - acc: 0.9538     \n",
      "Epoch 8/10\n",
      "41577/41577 [==============================] - 4s - loss: 0.1222 - acc: 0.9536     \n",
      "Epoch 9/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1202 - acc: 0.9534     \n",
      "Epoch 10/10\n",
      "41577/41577 [==============================] - 5s - loss: 0.1195 - acc: 0.9543     \n",
      "7500/8423 [=========================>....] - ETA: 0sEpoch 1/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1208 - acc: 0.9542     \n",
      "Epoch 2/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1105 - acc: 0.9570     \n",
      "Epoch 3/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1093 - acc: 0.9579     \n",
      "Epoch 4/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1080 - acc: 0.9582     \n",
      "Epoch 5/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1078 - acc: 0.9588     \n",
      "Epoch 6/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1055 - acc: 0.9599     \n",
      "Epoch 7/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1051 - acc: 0.9587     \n",
      "Epoch 8/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1042 - acc: 0.9600     \n",
      "Epoch 9/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1034 - acc: 0.9609     \n",
      "Epoch 10/10\n",
      "38789/38789 [==============================] - 4s - loss: 0.1030 - acc: 0.9610     \n",
      "10300/11211 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "39243/39243 [==============================] - 5s - loss: 0.1009 - acc: 0.9629     \n",
      "Epoch 2/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0907 - acc: 0.9663     \n",
      "Epoch 3/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0877 - acc: 0.9666     \n",
      "Epoch 4/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0866 - acc: 0.9677     \n",
      "Epoch 5/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0860 - acc: 0.9680     \n",
      "Epoch 6/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0862 - acc: 0.9678     \n",
      "Epoch 7/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0822 - acc: 0.9691     \n",
      "Epoch 8/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0830 - acc: 0.9694     \n",
      "Epoch 9/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0831 - acc: 0.9690     \n",
      "Epoch 10/10\n",
      "39243/39243 [==============================] - 4s - loss: 0.0820 - acc: 0.9692     \n",
      " 9700/10757 [==========================>...] - ETA: 0sEpoch 1/10\n",
      "40793/40793 [==============================] - 5s - loss: 0.1145 - acc: 0.9571     \n",
      "Epoch 2/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1067 - acc: 0.9600     \n",
      "Epoch 3/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1050 - acc: 0.9600     \n",
      "Epoch 4/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1041 - acc: 0.9605     \n",
      "Epoch 5/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1015 - acc: 0.9614     \n",
      "Epoch 6/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1027 - acc: 0.9617     \n",
      "Epoch 7/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1004 - acc: 0.9622     \n",
      "Epoch 8/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.1000 - acc: 0.9623     \n",
      "Epoch 9/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.0979 - acc: 0.9635     \n",
      "Epoch 10/10\n",
      "40793/40793 [==============================] - 4s - loss: 0.0973 - acc: 0.9633     \n",
      "8000/9207 [=========================>....] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.91952023608817601,\n",
       " [0.8975197126534874,\n",
       "  0.87403538083288546,\n",
       "  0.94781910814893156,\n",
       "  0.91558984967316237,\n",
       "  0.96263712913241384])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KerasSequential(keras_settings,\n",
    "                       [Dense(200, activation='relu', input_dim=618),\n",
    "                        Dense(200, activation='relu'),\n",
    "                        Dense(200, activation='relu'),\n",
    "                        Dense(200, activation='relu'),\n",
    "                        Dense(1, activation='sigmoid')\n",
    "                       ])\n",
    "cross_validate(model, data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('simple_keras_classifier.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
